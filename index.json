[{"content":"","date":"22 January 2024","permalink":"/Docs/","section":"SeesDisease","summary":"","title":"SeesDisease"},{"content":"Wissenstransfer # Das Konzept des Wissenstransfers, basierend auf der Methode der Wissensdestilierung, wie sie von Hinton et al. eingeführt wurde, zielt darauf ab, Wissen von einem größeren, komplexeren Modell (dem \u0026ldquo;Lehrer\u0026rdquo;) auf ein kleineres, effizienteres Modell (den \u0026ldquo;Schüler\u0026rdquo;) zu übertragen. Eine Evolution dieser Idee ist das Online-Model-Training, das von Guo et al. vorgestellt wurde, bei dem zwei Modelle gleichzeitig trainiert werden, ohne eine strikte Rollenverteilung zwischen Lehrer und Schüler festzulegen.\nDie hier beschriebene Methode erweitert und modifiziert das Konzept der Wissensdestilierung weiter, indem sie ein kleineres Modell als regulativen Term im Trainingsprozess des größeren Modells einsetzt. Diese Herangehensweise behält zwar die Grundprinzipien der Wissensdestilierung bei, differenziert sich jedoch durch die Implementierung signifikant unterschiedlicher Architekturen für die beiden Modelle. Ferner geht die Funktion des kleineren Modells über die eines herkömmlichen Schülermodells hinaus, indem es aktiv zur Regulierung und Beschränkung des Suchraums des größeren Modells beiträgt.\nSomit stellt diese Methode eine innovative Adaption und Integration der Prinzipien der Wissensdestilierung dar. Sie vereint die Konzepte des Online-Model-Trainings und der Consistency-Regularization, um eine effiziente und effektive Lernumgebung zu schaffen, die die Vorteile beider Ansätze nutzt: die Flexibilität und Effizienz des Wissenstransfers zwischen unterschiedlich konzipierten Modellen sowie die Stärkung der Lernprozesse durch die Einführung eines regulativen Elements.\nÜberblick über das Position-Proposal-Network (PPN) und die Zellsegmentierung # Das PPN-Modell verwendet zwei Tensoren, S für Bewertungen und R für Verschiebungsregressionen, basierend auf einem 2D-Gitter, das dem Originalbild zugeordnet ist, um präzise Positionsvorschläge und Verschiebungen zu generieren. Zusätzliche Tensoren, Sgt und Rgt, repräsentieren die Ground-Truth-Bewertungen und -Verschiebungen. Diese werden durch den Einsatz von Blob-Detection-Algorithmen auf Basis vollständiger Annotationen oder im weakly-supervised Training ermittelt. Der Verlust im PPN-Modell kombiniert den Focal-Binary Cross-Entropy-Loss für Bewertungen mit dem L2 Loss für Verschiebungsregressionen, was eine effiziente und genaue Positionierung und Segmentierung ermöglicht. Die Segmentierung nutzt die hochauflösenden Eigenschaften des Bildes für eine effiziente Verarbeitung von bis zu 4000 parallelen Segmentierungen pro Eingabebild. Durch das gezielte Aufheben der Translationsinvarianz von CNNs mittels Integration spezifischer Positionsdaten wird die Genauigkeit der Segmentierung einzelner Zellen basierend auf ihrer genauen Lage im Bild signifikant verbessert. Lernprozess, Semantische Segmentierung und Optimierung # Lernmechanismen und Segmentierung # Das Hauptmodell adaptiert semantische Segmentierungen vom Auxnet durch Berechnung der maximalen Logits der Instanzsegmentierungen an jedem Pixel, ergänzt durch Vorwissensversatz. Wahrscheinlichkeitsumwandlung und Integration von Vorwissen # Die Anwendung einer Sigmoid-Funktion ermöglicht die Transformation der Logits in Wahrscheinlichkeiten, wobei zweidimensionale Verteilungen zusätzliches Vorwissen über die Instanzgrößen integrieren. Optimierungsstrategien # Anstelle des Cross-Entropy-Loss wird für das Auxnet ein linearer Loss genutzt, der weiche Labels ohne feste 0 oder 1 Werte effektiver handhabt, was die semantische Segmentierung optimiert. Anpassungsreaktionen und Übersegmentierungsvermeidung # Anpassung an die Vorhersagesicherheit # Die Loss-Funktion des Modells passt sich der Sicherheit der Vorhersagen an, mit verstärkten Reaktionen bei hohen Sicherheitsgraden und abgeschwächten bei Unsicherheit, ähnlich dem Cross-Entropy-Loss aber mit spezifischer Reaktion auf die Vorhersagesicherheit. Strategien gegen Übersegmentierung # Eine spezielle Loss-Funktion fördert die Übereinstimmung der Segmentierung einzelner Instanzen mit der Gesamtsegmentierung und bestraft Überlappungen, um Übersegmentierung zu verhindern. Zellränder und Modellaktualisierung # Wissenstransfer für Zellränder # Zur Vorhersage von Zellrändern wird ein Sobel-Filter eingesetzt, der die segmentierten Vordergründe in Ränder umwandelt, mit einer anschließenden Anpassung durch tanh-Funktion zur Wertebegrenzung. Trainings- und Aktualisierungsprozess # Beide Modelle aktualisieren sich durch Standard-Gradientenabstieg, wobei sie unterschiedliche Loss-Funktionen für das Hauptmodell und das Auxnet anwenden, um die Trainingseffizienz zu optimieren. Vereinfachte Visualisierung # ","date":"22 January 2024","permalink":"/Docs/posts/training-des-w-loi-net/","section":"Posts","summary":"Die Methode verbessert die Wissensdestilierung, indem ein kleineres Modell den Lernprozess eines größeren Modells reguliert, was über traditionelle Lehrer-Schüler-Ansätze hinausgeht. Diese Technik kombiniert Online-Training und Konsistenzregulierung. Im PPN und der Zellsegmentierung werden genaue Positionsbestimmungen für eine zielgenaue Segmentierung genutzt, unterstützt durch spezifische Anpassungen im Lernprozess und Optimierungsstrategien gegen Übersegmentierung.","title":"Training W-LOI Net"},{"content":"Ergebnisse # LIVECell # In der vorliegenden Studie werden diverse maschinelle Lernmodelle anhand des LIVECell-Datensatzes evaluiert, einem der umfangreichsten annotierten Zelldatensätze, der acht unterschiedliche Zelllinien mit insgesamt etwa 1,6 Millionen Zellen umfasst.\nDie Modelle von Nishimura et al. [1] und Qu et al. [2] repräsentieren aktuelle weakly-supervised Ansätze in diesem Forschungsfeld, während das Modell von Edlund et al. [3] als fully-supervised Benchmark dient.\nDie Überlegenheit unserer Modelle W-LOI 1 und W-LOI 2 im Vergleich zu anderen weakly-supervised Modellen ist offensichtlich, da sie durchgängig bessere Ergebnisse liefern. Darüber hinaus erreichen unsere Modelle häufig Leistungen, die mit dem fully-supervised Ansatz von Edlund et al. vergleichbar oder sogar überlegen sind. Die Unterschiede zwischen W-LOI 1 und W-LOI 2 sind auf die jeweiligen Trainingsbedingungen zurückzuführen: W-LOI 1 wurde ausschließlich mit dem LIVECell-Datensatz trainiert, während W-LOI 2 zusätzlich mit Daten aus dem TissueNet-Datensatz vortrainiert wurde, was dessen Leistungsstärke weiter erhöht.\nTissueNet # [1] Kazuya Nishimura, Ryoma Bise. https://ieeexplore.ieee.org/document/10030481\n[2] Hui Qu, Pengxiang Wu, Qiaoying Huang, Jingru Yi, Zhennan Yan, Kang Li, Gregory M Riedlinger, Subhajyoti De, Shaoting Zhang, Dimitris N Metaxas. https://pubmed.ncbi.nlm.nih.gov/32746112/\n[3] Christoffer Edlund, Timothy R Jackson, Nabeel Khalid, Nicola Bevan, Timothy Dale, Andreas Dengel, Sheraz Ahmed, Johan Trygg, Rickard Sjögren. https://pubmed.ncbi.nlm.nih.gov/34462594/\n","date":"20 January 2024","permalink":"/Docs/posts/analyse-der-struktur/","section":"Posts","summary":"Hier werden die Ergebnisse auf den verschiedenen Datensätzen analysiert und verglichen. Auch werden verschiedene Ablationen durchgeführt, um die Wichtigkeit der einzelnen Komponenten zu untersuchen.","title":"Analyse des W-LOI Netzwerks"},{"content":"Encoder/Decoder-Struktur # Das Backbone-Modul verwendet eine Encoder/Decoder-Struktur, die essentiell für die Generierung von Feature-Repräsentationen des Eingabebildes in verschiedenen Auflösungen ist. Dies ermöglicht eine tiefergehende Analyse und Verarbeitung der Bilddaten. Die Bildeigenschaften sind in hellblau dargestellt. Die oberste Ebene, welche die Eigenschaften mit der niedrigsten Auflösung beinhaltet, ist hellrot gefärbt.\nEncoder # Das Backbone-Moduls des Encoders basiert auf ConvNeXt der Architektur, die für eine effiziente und effektive Feature-Extraktion aus den Eingabebildern sorgt. ConvNeXt ist speziell für die tiefgehende Analyse und Verarbeitung visueller Daten konzipiert und ermöglicht es, komplexe Muster und Strukturen in den Bildern zu erkennen und zu kodieren.\nDecoder # Für den Decoder-Teil wird ein Feature-Pyramid-Network (FPN) eingesetzt. Das FPN integriert die vom Encoder generierten Features auf verschiedenen Ebenen, um eine reichhaltige und skalierungsübergreifende Repräsentation zu erzeugen, die für die nachfolgenden Segmentierungsaufgaben nützlich ist.\nGrundlagen und Architektur des PPN # Das W-LOI-Net setzt auf ein Position-Proposal-Network (PPN), ein spezielles Convolutional-Neural-Network (CNN), das für weakly-supervised und unsupervised Training entwickelt wurde. Im Gegensatz zu herkömmlichen Region-Proposal-Networks (RPN) verzichtet das PPN auf die Nutzung von Bounding-Boxes und konzentriert sich ausschließlich auf die Bestimmung der Position von Locations of Interest (LOIs). Dies erfolgt durch die Erzeugung zweier Tensoren: Ein Bewertungstensor (S) für die Bewertung potenzieller Positionen und ein Tensor für Verschiebungsregressionen (R), die von einem 2D-Gitter des Originalbildes abgeleitet sind.\nTraining und Segmentierung im PPN # Für das Training des PPN werden zusätzliche Ground-Truth-Tensoren genutzt, um den PPN-Verlust zu bestimmen. Dabei wird ein Blob-Detection-Algorithmus eingesetzt, um bei vollständig annotierten Daten oder im weakly-supervised Training die Positionen zu identifizieren. Die Segmentierung erfolgt durch die Verwendung der detailliertesten Bildeigenschaften. Ein Schlüsselelement ist die gezielte Aufhebung der Translationsinvarianz im CNN durch Hinzufügung der Positionsdaten. Dies ermöglicht eine präzise Segmentierung, indem das Netzwerk spezifisch auf die Position jeder Zelle im Bild reagiert.\nPositionstensor # Der Output-Positionstensor kodiert präzise die räumlichen Koordinaten der Locations of Interest (LOIs) im Bildgitter. Er ermöglicht es dem Convolutional Neural Network (CNN), spezifische Bildbereiche für detaillierte Analysen oder Segmentierungen zu fokussieren, indem er die Translationsinvarianz des Netzwerks gezielt aufhebt. Dadurch wird eine hochpräzise Lokalisierung und Segmentierung von Objekten in komplexen Bildszenarien erreicht.\nArchitektur des Segmentierungsnetzwerks # Das Segmentierungsnetzwerk ist ein spezialisiertes Fully-Convolutional-Network (FCN) für Zellsegmentierung. Es kombiniert Eigenschafts- und Positionstensoren, wobei in den ersten Schichten Positionstensoren ignoriert werden, um Effizienz und Speicher zu optimieren. In den letzten Schichten wird der Positionstensor für eine genauere Segmentierung hinzugefügt. Zudem werden Daten um die Lokalisationen von Interesse (LOIs) zu kleineren Patches zurechtgeschnitten, was unnötige Berechnungen reduziert. Die finale Schicht skaliert das Bild mittels Transposed Convolution zurück auf Originalgröße.\nKernaspekte des Segmentierungsprozesses # Die Effizienz des Netzwerks basiert auf der frühen Ignorierung und späteren Einbeziehung der Positionstensoren, was zu präziser Lokalisierung und Segmentierung führt. Das Zurechtschneiden der Daten fokussiert auf die relevante Zellregion, wodurch die Genauigkeit erhöht und Ressourcen gespart werden. Die abschließende Skalierung stellt die ursprüngliche Bildgröße sicher und bewahrt die Bildqualität.\n","date":"20 January 2024","permalink":"/Docs/posts/architektur-w-loi-net/","section":"Posts","summary":"Die beschriebene Technologie umfasst eine Encoder/Decoder-Struktur mit ConvNeXt und FPN für tiefgehende Bildanalyse, ein Position-Proposal-Network (PPN) zur präzisen Lokalisierung ohne Bounding-Boxes, und ein spezialisiertes Fully-Convolutional-Network (FCN) für effiziente Zellsegmentierung. Diese Kombination ermöglicht effektive Bildverarbeitung und -segmentierung durch fortschrittliche Feature-Extraktion und gezielte Analyse von Interessensbereichen.","title":"Architektur W-LOI-Net"},{"content":" Encoder: # Der Encoder, dargestellt in hellgrau, ist aus mehreren Modulen zusammengesetzt, die schrittweise tiefer in das Netzwerk führen. Jedes Modul verfeinert und verdichtet die Informationen weiter. Am Ende des Encoders werden die Ergebnisse aller Stufen zu einer kompakten Merkmalskarte zusammengefasst, die anschließend an den Decoder übergeben wird.\nDecoder: # Der Decoder-Teil, in dunkelgrau gehalten, zielt darauf ab, aus der vom Encoder übermittelten Merkmalskarte eine sinnvolle Ausgabe zu rekonstruieren. Im Gegensatz zum Encoder sind die Prozesse hier darauf ausgelegt, die Dimensionalität und die räumliche Auflösung der Merkmale zu erhöhen, um ein endgültiges Ergebnis, wie beispielsweise ein Bild, zu formen.\nArchitektur: # Das DEPooling-Net ist durch mehrere Stufen charakterisiert, die das Netzwerk grafisch in die Breite ziehen. Anstatt jede Stufe des Encoders mit einer entsprechenden Stufe des Decoders zu verknüpfen, erfolgt eine Konkatenation, um alle Features jeder Stufe in einer Feature-Map zu vereinen. Diese Feature-Map wird dann in den Decoder überführt und kann als komplette Sammlung der bis dato extrahierten Features betrachtet werden. Im Encoder werden nicht die Features der SepConvs, sondern jene der DEPooling-Module für die Weiterverarbeitung verwendet, da dies zu besseren Ergebnissen führt. Die im Decoder verarbeiteten Features werden schließlich an die Dimensionen des Inputs angepasst. Optional können in den oberen Teil des Decoders zusätzliche Features aus dem Encoder eingespeist werden, um potentiellen Informationsverlust zu minimieren.\n","date":"20 January 2024","permalink":"/Docs/posts/depooling-encoder-decoder/","section":"Posts","summary":"Ein kürzer Überblick über das DEPooling-Net.","title":"Das DEPooling-Net im Überblick"},{"content":" URDE-Net: # Das URDE-Net ist ein auf U-Net basierendes Restaurationsnetzwerk, speziell entwickelt für die Restaurierung medizinischer Bilder. Es besteht aus einem Encoder- und einem Decoder-Teil, wobei es Features aus zunehmend tieferen Ebenen extrahiert und diese in den parallelen Stufen des Decoders wieder zu einem vollständigen Bild rekonstruiert.\nRestaurations-Block: # Das Kernmodul des URDE-Nets ist der Restaurations-Block, bestehend aus einer Reihe aufeinanderfolgender Schichten. Eine 1x1 Convolution passt die eingehenden Features auf eine bestimmte Dimension an, gefolgt von einer 3x3 Convolution und der Mish-Aktivierungsfunktion. Innerhalb dieses Moduls wird Efficient-Attention integriert, um wichtige Features hervorzuheben. Anschließend folgen 1x1 Pointwise-Convolutions, wobei eine Skip-Connection eingebaut wird, um die Features aus früheren Schichten in die Verarbeitung einzubeziehen.\nEncoder-Block: # Jede Stufe des Encoder beinhaltet einen EncBlock, der aus einer Sequenz von Modulen besteht. Zunächst wird der Restaurations-Block zur Bildwiederherstellung eingesetzt. Danach folgt ein DEPooling-Modul zur Extraktion wertvoller Merkmale und zur Reduktion der räumlichen Dimensionen. Schließlich wird Efficient Attention genutzt, um diese Merkmale für die Verarbeitung in der nächsten Decoder-Stufe hervorzuheben.\nDecoder-Block: # Im Gegensatz zu den Encoder-Modulen beginnt das Decoder-Modul mit einer 3x3 dilatierten Convolution, um das rezeptive Feld zu erweitern. Danach folgt wiederum der Restaurations-Block, der hier jedoch nicht tiefer in die Materie eindringt. Die Dimensionen des Inputs entsprechen hierbei denen des Outputs.\n","date":"20 January 2024","permalink":"/Docs/posts/urde-net/","section":"Posts","summary":"Die Bild restauration mit dem URDE-Net.","title":"Das URDE-Net im Überblick"},{"content":" Simple-Conv-Modul: # Das Simple-Conv-Modul ist ein zentraler Bestandteil vieler Module im DEPooling-Net. Es zielt darauf ab, Features zu extrahieren und die Eingabedaten in tiefere Dimensionen zu transformieren. Dies wird durch die Verwendung einer 3x3 Convolution erreicht, gefolgt von Batch-Normalisierung und der Mish-Aktivierungsfunktion.\nRes-Conv-Modul: # Im DEPooling-Net spielt das Res-Conv-Modul, ein Residual-Modul, eine Schlüsselrolle, da es als essenzieller Bestandteil in modernen CNN-Architekturen gilt. Diese Module verbessern nicht nur die Feature-Extraktion signifikant, sondern tragen auch zur Netzwerkstabilität bei, indem sie den Gradientenfluss optimieren. Die Integration von Skip-Connections, die Informationen aus früheren Schichten mit denen tieferer Schichten effizient verknüpfen, ist dabei von besonderer Bedeutung. Durch die Einführung von Dilatation erweitern diese Module das rezeptive Feld und ermöglichen eine genauere Feature-Extraktion, wobei die Genauigkeit durch sorgfältige Implementierung gewahrt wird.\nAdaptive-Average-Pooling: # Das Adaptive-Average-Pooling-Modul kommt im letzten Teil des Decoders zum Einsatz. Es extrahiert wichtige Features der zuvor erfassten Merkmale, unabhängig von der Eingabegröße. Im DEPooling-Net dient es dazu, die Höhe und Breite der Features auf ein Minimum zu reduzieren.\nDEPooling: # Durch die Nutzung dilatierter Convolutions erweitert das DEPooling-Modul das rezeptive Feld, um Informationsverlust zu minimieren. Diese Technik fängt Kontextinformationen detailliert auf, ohne die räumliche Auflösung des Inputs zu beeinträchtigen. Eine nachfolgende 2x2 Max-Pooling-Schicht reduziert die Dimensionen, während essentielle Merkmale erhalten bleiben. Die Mish-Aktivierungsfunktion verarbeitet diese Outputs weiter und unterstützt eine effiziente Neuronenaktivierung. Das DEPooling-Modul erhält so die Detailtreue des Inputs bei gleichzeitiger Optimierung für nachfolgende Schichten.\nDepthwise-Separable-Convolution: # Diese Technik unterteilt sich in zwei Schritte: Zuerst wird eine Depthwise-Convolution durchgeführt, wobei jeder Eingangskanal separat mit einer 3x3 gruppierten Convolution bearbeitet wird. Die Gruppierung basiert auf dem größten gemeinsamen Teiler von Eingangs- und Ausgangskanälen. Anschließend erfolgt eine Pointwise-Convolution mit einer 1x1 Convolution, die die Ergebnisse der Depthwise-Convolution zusammenführt, um die Netzwerktiefe zu erhöhen und komplexere Features zu extrahieren. In unserer Architektur ersetzen dilatierte Convolutions herkömmliche Convolutions, wobei jeder Depthwise-Convolution-Schicht eine spezifische Dilationsrate zugeordnet ist, die in tieferen Schichten progressiv ansteigt, um eine differenzierte und effiziente Extraktion von Merkmalen aus den Eingabe-Feature-Maps zu ermöglichen.\n","date":"20 January 2024","permalink":"/Docs/posts/depooling-module/","section":"Posts","summary":"Simple-Conv-Modul: # Das Simple-Conv-Modul ist ein zentraler Bestandteil vieler Module im DEPooling-Net. Es zielt darauf ab, Features zu extrahieren und die Eingabedaten in tiefere Dimensionen zu transformieren. Dies wird durch die Verwendung einer 3x3 Convolution erreicht, gefolgt von Batch-Normalisierung und der Mish-Aktivierungsfunktion.","title":"Die Module des DEPooling-Nets im Überblick"},{"content":"","date":"13 June 2022","permalink":"/Docs/posts/","section":"Posts","summary":"","title":"Posts"},{"content":"","date":"1 January 0001","permalink":"/Docs/authors/","section":"Authors","summary":"","title":"Authors"},{"content":"","date":"1 January 0001","permalink":"/Docs/categories/","section":"Categories","summary":"","title":"Categories"},{"content":"","date":"1 January 0001","permalink":"/Docs/series/","section":"Series","summary":"","title":"Series"},{"content":"","date":"1 January 0001","permalink":"/Docs/tags/","section":"Tags","summary":"","title":"Tags"}]